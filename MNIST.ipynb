# -*- coding: utf-8 -*-
"""MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BhJdzVjsXL_mCoVb6ZNgxfbunUc6l3Xo

importing tensorflow and keras
"""

import tensorflow as tf

from tensorflow import keras

import matplotlib.pyplot as plt

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

import numpy as np

"""importing mnist dataset from keras"""

(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()

len(X_train)

len(y_train)

len(X_test)

X_train[0].shape

y_train[4]

plt.matshow(X_train[4])

"""VERY IMPORTANT STEP TO NORMALISE THE VECTOR (IN BETWEEN 0 AND 1)"""

X_train = X_train / 255
X_test = X_test / 255

X_train_flattened = X_train.reshape(len(X_train),28*28)

X_train_flattened.shape

X_test_flattened = X_test.reshape(len(X_test),28*28)

model = keras.Sequential([keras.layers.Dense(10, input_shape=(784,),activation="sigmoid")])

model.compile(optimizer="adam",loss ='sparse_categorical_crossentropy',metrics='accuracy')

model.fit(X_train_flattened,y_train,epochs=8)

model.evaluate(X_test_flattened,y_test)

y_predicted = model.predict(X_test_flattened)

y_predicted[0]

plt.matshow(X_test[9])

np.argmax(y_predicted[9])

y_predicted_labels = [np.argmax(i) for i in y_predicted]

cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)
cm

import seaborn as sn
plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""USING HIDDEN LAYERS

"""

#model1 = keras.Sequential([
 #   keras.layers.Dense(100, input_shape=(784,), activation='relu'),
  #  keras.layers.Dense(10, activation='relu')
#])
#here last layer should be sigmoid or less accuracy since we are trying to get probabilities

#model1.compile(optimizer="adam",loss="sparse_categorical_crossentropy",metrics=['accuracy'])

#model1.fit(X_train_flattened,y_train,epochs=8)

model = keras.Sequential([
    keras.layers.Dense(100, input_shape=(784,), activation='relu'),
    keras.layers.Dense(10, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(X_train_flattened, y_train, epochs=5)

model.evaluate(X_test_flattened,y_test)

y_predicted = model.predict(X_test_flattened)
y_predicted_labels = [np.argmax(i) for i in y_predicted]
cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)

plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

"""USING FLATTEN SO THAT WE DONT HAVE TO CALL RESHAPE"""

model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(100, activation='relu'),
    keras.layers.Dense(10, activation='sigmoid')
])

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(X_train, y_train, epochs=10)

model.evaluate(X_test,y_test)

y_predicted = model.predict(X_test_flattened)
y_predicted_labels = [np.argmax(i) for i in y_predicted]
cm = tf.math.confusion_matrix(labels=y_test,predictions=y_predicted_labels)

plt.figure(figsize = (10,7))
sn.heatmap(cm, annot=True, fmt='d')
plt.xlabel('Predicted')
plt.ylabel('Truth')

